import os
import re
import json
import zipfile
import threading
import tkinter as tk
from tkinter import filedialog, messagebox
from tkinter import ttk
from typing import Dict, List, Set, Iterable, Callable, Optional

import xml.etree.ElementTree as ET

# ============ –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ============

DEFAULT_CHATGPT_MODEL = "gpt-4.1-mini"
CHATGPT_MODELS = [
    "gpt-4.1-mini",
    "gpt-4.1",
    "gpt-4o-mini",
    "gpt-4o",
    "gpt-5.1",
    "gpt-5-mini",
]

# –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–µ—Ä–µ–≤–æ–¥–∞: –≥—Ä—É–∑–∏–Ω—Å–∫–∏–π -> —Ü–µ–ª–µ–≤–æ–π —è–∑—ã–∫
DIRECTION_CONFIG: Dict[str, Dict[str, str]] = {
    "ka-ru": {
        "label": "–ì—Ä—É–∑–∏–Ω—Å–∫–∏–π ‚Üí –†—É—Å—Å–∫–∏–π",
        "target_language": "Russian",
        "suffix": "_ru",
        "local_model": "Helsinki-NLP/opus-mt-ka-ru",
    },
    "ka-en": {
        "label": "–ì—Ä—É–∑–∏–Ω—Å–∫–∏–π ‚Üí –ê–Ω–≥–ª–∏–π—Å–∫–∏–π",
        "target_language": "English",
        "suffix": "_en",
        "local_model": "Helsinki-NLP/opus-mt-ka-en",
    },
}

# –¥–∏–∞–ø–∞–∑–æ–Ω—ã Unicode –¥–ª—è –≥—Ä—É–∑–∏–Ω—Å–∫–æ–≥–æ
GEORGIAN_RE = re.compile(r"[\u10A0-\u10FF\u1C90-\u1CBF]+")


# ============ –£—Ç–∏–ª–∏—Ç—ã ============

def is_docx(path: str) -> bool:
    return path.lower().endswith(".docx")


def is_xlsx(path: str) -> bool:
    return path.lower().endswith(".xlsx")


def chunks(lst: List[str], n: int) -> Iterable[List[str]]:
    for i in range(0, len(lst), n):
        yield lst[i:i + n]


def load_api_key_from_env_file(env_path: str) -> str:
    """
    –ß–∏—Ç–∞–µ—Ç .env-—Ñ–∞–π–ª –∏ –∏—â–µ—Ç OPENAI_API_KEY / API_KEY.
    –ï—Å–ª–∏ –Ω–µ –Ω–∞—à—ë–ª ‚Äî –±–µ—Ä—ë—Ç –ø–µ—Ä–≤—É—é –Ω–µ–ø—É—Å—Ç—É—é, –Ω–µ–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å—Ç—Ä–æ–∫—É –∫–∞–∫ –∫–ª—é—á.
    """
    if not os.path.exists(env_path):
        raise FileNotFoundError(f".env —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {env_path}")

    candidate = None
    with open(env_path, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line or line.startswith("#"):
                continue
            if "=" in line:
                k, v = line.split("=", 1)
                k = k.strip()
                v = v.strip()
                if k in ("OPENAI_API_KEY", "API_KEY"):
                    return v
                if candidate is None and v:
                    candidate = v
            else:
                if candidate is None:
                    candidate = line

    if not candidate:
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∫–ª—é—á API –∏–∑ .env —Ñ–∞–π–ª–∞.")
    return candidate


def get_direction_code_from_label(label: str) -> str:
    for code, meta in DIRECTION_CONFIG.items():
        if meta["label"] == label:
            return code
    raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–¥–∞: {label}")


# ============ –†–∞–±–æ—Ç–∞ —Å XML –≤–Ω—É—Ç—Ä–∏ DOCX/XLSX ============

def collect_docx_items(path: str) -> List[Dict[str, object]]:
    """
    DOCX ‚Äî —Ä–∞–±–æ—Ç–∞–µ–º –ø–æ –ê–ë–ó–ê–¶–ê–ú (<w:p>), –Ω–æ —Ç–µ–ø–µ—Ä—å —Å–æ–±–∏—Ä–∞–µ–º –Ω–µ –ø—Ä–æ—Å—Ç–æ —Ç–µ–∫—Å—Ç—ã,
    –∞ –ü–û–õ–ù–´–ô —Å–ø–∏—Å–æ–∫ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω—ã–º–∏ ID.

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π:
      {
        "id": "word/document.xml::p17",
        "xml_name": "word/document.xml",
        "p_index": 17,
        "full_text": "<–≤–µ—Å—å —Ç–µ–∫—Å—Ç –∞–±–∑–∞—Ü–∞ –∫–∞–∫ –µ—Å—Ç—å>",
        "clean_text": "<full_text.strip()>"
      }

    –°–æ–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ –∞–±–∑–∞—Ü—ã, –≤ –∫–æ—Ç–æ—Ä—ã—Ö –µ—Å—Ç—å –≥—Ä—É–∑–∏–Ω—Å–∫–∏–π —Ç–µ–∫—Å—Ç.
    """
    items: List[Dict[str, object]] = []

    with zipfile.ZipFile(path, "r") as zin:
        for info in zin.infolist():
            fname = info.filename
            if not (fname.startswith("word/") and fname.lower().endswith(".xml")):
                continue

            xml_bytes = zin.read(fname)
            try:
                root = ET.fromstring(xml_bytes)
            except Exception:
                continue

            m = re.match(r"\{(.*)\}", root.tag)
            ns = m.group(1) if m else ""
            p_tag = f"{{{ns}}}p"
            t_tag = f"{{{ns}}}t"

            for p_index, p in enumerate(root.iter(p_tag)):
                t_elems = list(p.iter(t_tag))
                if not t_elems:
                    continue

                parts = [(t.text or "") for t in t_elems]
                full_text = "".join(parts)
                if not full_text:
                    continue

                if not GEORGIAN_RE.search(full_text):
                    continue

                clean_text = full_text.strip()
                if not clean_text:
                    continue

                item_id = f"{fname}::p{p_index}"
                items.append({
                    "id": item_id,
                    "xml_name": fname,
                    "p_index": p_index,
                    "full_text": full_text,
                    "clean_text": clean_text,
                })

    print(f"üìÑ DOCX: –Ω–∞–π–¥–µ–Ω–æ {len(items)} –∞–±–∑–∞—Ü–µ–≤ —Å –≥—Ä—É–∑–∏–Ω—Å–∫–∏–º —Ç–µ–∫—Å—Ç–æ–º.")
    return items


def collect_georgian_fragments_from_xml_bytes(xml_bytes: bytes) -> Set[str]:
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: –Ω–∞—Ö–æ–¥–∏–º –≤—Å–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —É–∑–ª—ã, —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ –≥—Ä—É–∑–∏–Ω—Å–∫–∏–π,
    –∏ –±–µ—Ä—ë–º –∏—Ö –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Ü–µ–ª–∏–∫–æ–º (strip()).
    """
    result: Set[str] = set()
    try:
        root = ET.fromstring(xml_bytes)
    except Exception:
        return result

    for elem in root.iter():
        text = elem.text
        if not text:
            continue
        if GEORGIAN_RE.search(text):
            cleaned = text.strip()
            if cleaned:
                result.add(cleaned)
    return result


def collect_fragments_xlsx(path: str) -> Set[str]:
    """
    XLSX ‚Äî –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º sharedStrings + worksheets.
    workbook.xml (–∏–º–µ–Ω–∞ –ª–∏—Å—Ç–æ–≤) –Ω–µ —Ç—Ä–æ–≥–∞–µ–º.
    """
    to_translate: Set[str] = set()

    with zipfile.ZipFile(path, "r") as zin:
        for info in zin.infolist():
            fname = info.filename.lower()

            if fname.startswith("xl/sharedstrings") and fname.endswith(".xml"):
                xml_bytes = zin.read(info.filename)
            elif fname.startswith("xl/worksheets/") and fname.endswith(".xml"):
                xml_bytes = zin.read(info.filename)
            else:
                continue

            frags = collect_georgian_fragments_from_xml_bytes(xml_bytes)
            to_translate.update(frags)

    print(f"üìä XLSX: –Ω–∞–π–¥–µ–Ω–æ {len(to_translate)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≥—Ä—É–∑–∏–Ω—Å–∫–∏—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤.")
    return to_translate


def replace_georgian_in_xml_bytes(xml_bytes: bytes, mapping: Dict[str, str]) -> bytes:
    """
    –î–ª—è XLSX: –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç —É–∑–ª–∞ (strip) –µ—Å—Ç—å –≤ mapping ‚Äî –∑–∞–º–µ–Ω—è–µ–º —Ü–µ–ª–∏–∫–æ–º,
    —Å–æ—Ö—Ä–∞–Ω—è—è –≤–µ–¥—É—â–∏–µ/—Ö–≤–æ—Å—Ç–æ–≤—ã–µ –ø—Ä–æ–±–µ–ª—ã.
    """
    try:
        root = ET.fromstring(xml_bytes)
    except Exception:
        return xml_bytes

    for elem in root.iter():
        text = elem.text
        if not text:
            continue

        stripped = text.strip()
        if stripped in mapping:
            prefix_len = len(text) - len(text.lstrip())
            suffix_len = len(text) - len(text.rstrip())
            prefix = text[:prefix_len]
            suffix = text[len(text) - suffix_len:] if suffix_len > 0 else ""
            new_text = mapping[stripped]
            elem.text = f"{prefix}{new_text}{suffix}"

    return ET.tostring(root, encoding="utf-8", xml_declaration=True)


def process_docx_xml_paragraphs(
    xml_bytes: bytes,
    xml_name: str,
    id_mapping: Dict[str, str],
) -> bytes:
    """
    –ü—Ä–æ–±–µ–≥–∞–µ–º –ø–æ <w:p> –≤ –æ–¥–Ω–æ–º XML-—Ñ–∞–π–ª–µ DOCX –∏, –µ—Å–ª–∏ –¥–ª—è –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞ –µ—Å—Ç—å
    –ø–µ—Ä–µ–≤–æ–¥ –≤ id_mapping, –ø–æ–¥–º–µ–Ω—è–µ–º –µ–≥–æ —Ç–µ–∫—Å—Ç. –ü—Ä–∏ —ç—Ç–æ–º:
      - –µ—Å–ª–∏ –≤ —Ç–µ–∫—É—â–µ–º –∞–±–∑–∞—Ü–µ —É–∂–µ –ù–ï–¢ –≥—Ä—É–∑–∏–Ω—Å–∫–∏—Ö –±—É–∫–≤, –º—ã –µ–≥–æ –ù–ï —Ç—Ä–æ–≥–∞–µ–º,
        –¥–∞–∂–µ –µ—Å–ª–∏ –µ–≥–æ ID –µ—Å—Ç—å –≤ id_mapping (–∑–∞—â–∏—Ç–∞ –æ—Ç –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –ø—Ä–æ–≥–æ–Ω–∞
        –ø–æ —É–∂–µ –ø–µ—Ä–µ–≤–µ–¥—ë–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É / –≤—Ä—É—á–Ω—É—é –ø–µ—Ä–µ–≤–µ–¥—ë–Ω–Ω—ã–º –∫—É—Å–∫–∞–º).
    """
    try:
        root = ET.fromstring(xml_bytes)
    except Exception:
        return xml_bytes

    m = re.match(r"\{(.*)\}", root.tag)
    ns = m.group(1) if m else ""
    p_tag = f"{{{ns}}}p"
    t_tag = f"{{{ns}}}t"

    for p_index, p in enumerate(root.iter(p_tag)):
        para_id = f"{xml_name}::p{p_index}"
        if para_id not in id_mapping:
            continue

        t_elems = list(p.iter(t_tag))
        if not t_elems:
            continue

        orig_parts = [(t.text or "") for t in t_elems]
        orig_full = "".join(orig_parts)
        if not orig_full:
            continue

        # üîí –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ú–ï–°–¢–û:
        # –µ—Å–ª–∏ –í –≠–¢–û–ú –ê–ë–ó–ê–¶–ï —É–∂–µ –Ω–µ—Ç –≥—Ä—É–∑–∏–Ω—Å–∫–∏—Ö –±—É–∫–≤ ‚Äî –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
        if not GEORGIAN_RE.search(orig_full):
            continue

        translated_clean = id_mapping[para_id]

        # –¥–µ–±–∞–≥
        #print("\n=== RAW TRANSLATION BEFORE SPLIT ===")
        #print("ID:", para_id)
        #print("ORIGINAL:", repr(orig_full))
        #print("TRANSLATED:", repr(translated_clean))
        #print("====================================\n")

        # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤–µ–¥—É—â–∏–µ/—Ö–≤–æ—Å—Ç–æ–≤—ã–µ –ø—Ä–æ–±–µ–ª—ã –∞–±–∑–∞—Ü–∞
        lead = len(orig_full) - len(orig_full.lstrip())
        trail = len(orig_full) - len(orig_full.rstrip())
        prefix = orig_full[:lead]
        suffix = orig_full[len(orig_full) - trail:] if trail > 0 else ""
        translated_full = prefix + translated_clean + suffix

        # --- –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –£–ü–†–û–©–ï–ù–ò–ï ---
        # –í–µ—Å—å —Ç–µ–∫—Å—Ç –∞–±–∑–∞—Ü–∞ –∫–ª–∞–¥—ë–º –≤ –ø–µ—Ä–≤—ã–π <w:t>, –æ—Å—Ç–∞–ª—å–Ω—ã–µ —á–∏—Å—Ç–∏–º.
        t_elems[0].text = translated_full
        for t in t_elems[1:]:
            t.text = ""
        # ------------------------------

    return ET.tostring(root, encoding="utf-8", xml_declaration=True)

def debug_scan_docx_for_georgian(path: str, max_examples: int = 20) -> None:
    """
    –û—Ç–ª–∞–¥–æ—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: —Å–∫–∞–Ω–∏—Ä—É–µ—Ç DOCX –∏ –∏—â–µ—Ç –≤—Å–µ –∞–±–∑–∞—Ü—ã, –≥–¥–µ –æ—Å—Ç–∞–ª—Å—è –≥—Ä—É–∑–∏–Ω—Å–∫–∏–π —Ç–µ–∫—Å—Ç.
    –ü–µ—á–∞—Ç–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä–æ–≤ (–∫—É—Å–æ—á–µ–∫ —Ç–µ–∫—Å—Ç–∞ + –∏–º—è XML-—Ñ–∞–π–ª–∞ + –∏–Ω–¥–µ–∫—Å –∞–±–∑–∞—Ü–∞).
    """
    count = 0
    examples = []

    with zipfile.ZipFile(path, "r") as zin:
        for info in zin.infolist():
            fname = info.filename
            if not (fname.startswith("word/") and fname.lower().endswith(".xml")):
                continue

            xml_bytes = zin.read(fname)
            try:
                root = ET.fromstring(xml_bytes)
            except Exception:
                continue

            m = re.match(r"\{(.*)\}", root.tag)
            ns = m.group(1) if m else ""
            p_tag = f"{{{ns}}}p"
            t_tag = f"{{{ns}}}t"

            for p_index, p in enumerate(root.iter(p_tag)):
                parts = []
                for t in p.iter(t_tag):
                    parts.append(t.text or "")
                full_text = "".join(parts)
                if not full_text:
                    continue
                if GEORGIAN_RE.search(full_text):
                    count += 1
                    if len(examples) < max_examples:
                        snippet = full_text.strip()
                        if len(snippet) > 120:
                            snippet = snippet[:117] + "..."
                        examples.append((fname, p_index, snippet))

    print(f"üîç –í —Ñ–∞–π–ª–µ {os.path.basename(path)} –æ—Å—Ç–∞–ª–æ—Å—å –∞–±–∑–∞—Ü–µ–≤ —Å –≥—Ä—É–∑–∏–Ω—Å–∫–∏–º: {count}")
    for fname, p_index, snippet in examples:
        print(f"  - {fname}::p{p_index}: {snippet}")


def apply_translations_docx(
    input_path: str,
    output_path: str,
    id_mapping: Dict[str, str],
    text_mapping: Optional[Dict[str, str]] = None,
    progress_callback: Optional[Callable[[float, str], None]] = None,
    start: float = 90.0,
    end: float = 100.0,
) -> None:
    with zipfile.ZipFile(input_path, "r") as zin, \
         zipfile.ZipFile(output_path, "w", compression=zipfile.ZIP_DEFLATED) as zout:

        infos = zin.infolist()
        total = len(infos)
        changed = 0

        for idx, info in enumerate(infos, start=1):
            fname = info.filename
            data = zin.read(fname)

            new_data = data

            # 1) –¥–ª—è word/*.xml –ø—Ä–æ–≥–æ–Ω—è–µ–º –∞–±–∑–∞—Ü—ã —Å id_mapping
            if fname.startswith("word/") and fname.lower().endswith(".xml"):
                new_data = process_docx_xml_paragraphs(new_data, fname, id_mapping)

            # 2) –¥–ª—è –õ–Æ–ë–û–ì–û *.xml (–≤–∫–ª—é—á–∞—è word/*.xml, docProps –∏ —Ç.–ø.) ‚Äî
            #    –æ–±—â–∞—è –∑–∞–º–µ–Ω–∞ –ø–æ text_mapping
            if fname.lower().endswith(".xml") and text_mapping:
                new_data = replace_georgian_in_xml_bytes(new_data, text_mapping)

            if new_data != data:
                changed += 1

            zout.writestr(info, new_data)

            if progress_callback and total > 0:
                frac = idx / total
                pct = start + (end - start) * frac
                progress_callback(pct, "–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–¥–∞ –≤ DOCX...")

    print(f"üíæ DOCX —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {output_path}, –∏–∑–º–µ–Ω—ë–Ω–Ω—ã—Ö XML: {changed}")

def apply_translations_xlsx(
    input_path: str,
    output_path: str,
    text_mapping: Dict[str, str],
    progress_callback: Optional[Callable[[float, str], None]] = None,
    start: float = 90.0,
    end: float = 100.0,
) -> None:
    """
    –ë–µ–∑–æ–ø–∞—Å–Ω–æ –ø—Ä–∏–º–µ–Ω—è–µ—Ç –ø–µ—Ä–µ–≤–æ–¥—ã –∫ XLSX —á–µ—Ä–µ–∑ openpyxl.

    text_mapping: {–∏—Å—Ö–æ–¥–Ω—ã–π_–≥—Ä—É–∑–∏–Ω—Å–∫–∏–π_—Ç–µ–∫—Å—Ç_strip -> –ø–µ—Ä–µ–≤–æ–¥}

    –õ–æ–≥–∏–∫–∞:
      - –æ—Ç–∫—Ä—ã–≤–∞–µ–º –∫–Ω–∏–≥—É —á–µ—Ä–µ–∑ openpyxl;
      - –¥–ª—è –≤—Å–µ—Ö —è—á–µ–µ–∫ —Å–æ —Å—Ç—Ä–æ–∫–æ–≤—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º:
          * –±–µ—Ä—ë–º value;
          * –¥–µ–ª–∞–µ–º stripped = value.strip();
          * –µ—Å–ª–∏ stripped –µ—Å—Ç—å –≤ text_mapping ‚Äî –ø–æ–¥–º–µ–Ω—è–µ–º, –∞–∫–∫—É—Ä–∞—Ç–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è—è
            –≤–µ–¥—É—â–∏–µ/—Ö–≤–æ—Å—Ç–æ–≤—ã–µ –ø—Ä–æ–±–µ–ª—ã;
      - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ output_path.
    """
    from openpyxl import load_workbook

    # –û—Ç–∫—Ä—ã–≤–∞–µ–º –∫–Ω–∏–≥—É
    wb = load_workbook(input_path, data_only=False)

    # –°—á–∏—Ç–∞–µ–º –æ–±—â–µ–µ —á–∏—Å–ª–æ —è—á–µ–µ–∫ –¥–ª—è –±–æ–ª–µ–µ-–º–µ–Ω–µ–µ —á–µ—Å—Ç–Ω–æ–≥–æ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
    total_cells = 0
    for ws in wb.worksheets:
        for row in ws.iter_rows():
            total_cells += len(row)
    if total_cells == 0:
        total_cells = 1  # –∑–∞—â–∏—Ç–∞ –æ—Ç –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å

    processed = 0
    changed_cells = 0

    for ws in wb.worksheets:
        for row in ws.iter_rows():
            for cell in row:
                val = cell.value
                if isinstance(val, str):
                    original = val
                    stripped = val.strip()
                    if stripped in text_mapping:
                        new_core = text_mapping[stripped]

                        # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤–µ–¥—É—â–∏–µ/—Ö–≤–æ—Å—Ç–æ–≤—ã–µ –ø—Ä–æ–±–µ–ª—ã
                        prefix_len = len(original) - len(original.lstrip())
                        suffix_len = len(original) - len(original.rstrip())
                        prefix = original[:prefix_len]
                        suffix = original[len(original) - suffix_len:] if suffix_len > 0 else ""

                        cell.value = f"{prefix}{new_core}{suffix}"
                        changed_cells += 1

                processed += 1
                if progress_callback:
                    frac = processed / total_cells
                    pct = start + (end - start) * frac
                    progress_callback(pct, "–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–¥–∞ –≤ XLSX...")

    wb.save(output_path)
    print(f"üíæ XLSX —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {output_path}, –∏–∑–º–µ–Ω—ë–Ω–Ω—ã—Ö —è—á–µ–µ–∫: {changed_cells}")



# ============ –ü–µ—Ä–µ–≤–æ–¥—á–∏–∫–∏ ============

def translate_with_chatgpt(
    fragments: List[str],
    model_name: str,
    api_key: str,
    target_language: str,
    progress_callback: Optional[Callable[[float, str], None]] = None,
    start: float = 10.0,
    end: float = 90.0,
) -> Dict[str, str]:
    """
    –ü–µ—Ä–µ–≤–æ–¥ –≥—Ä—É–∑–∏–Ω—Å–∫–∏—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ ChatGPT (OpenAI API).
    –ù–û–í–ê–Ø –í–ï–†–°–ò–Ø:
      - –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∏—Å—Ö–æ–¥–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã –∫–∞–∫ JSON-–∫–ª—é—á–∏;
      - –≤–º–µ—Å—Ç–æ —ç—Ç–æ–≥–æ —à–ª—ë—Ç —Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ {id, text};
      - –º–æ–¥–µ–ª—å –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç translations: [{id, text}, ...];
      - –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–æ–≥–æ —Å—Ç—Ä–æ–∏–º mapping {–æ—Ä–∏–≥–∏–Ω–∞–ª: –ø–µ—Ä–µ–≤–æ–¥}.
    """
    from openai import OpenAI

    os.environ["OPENAI_API_KEY"] = api_key
    client = OpenAI()

    # 1) –ß–∏—Å—Ç–∏–º –∏ –¥–µ–¥—É–ø–ª–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç—ã
    cleaned = []
    for f in fragments:
        s = (f or "").strip()
        if s:
            cleaned.append(s)

    # —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã, —á—Ç–æ–±—ã –Ω–µ –ø–ª–∞—Ç–∏—Ç—å –¥–≤–∞–∂–¥—ã –∑–∞ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –∞–±–∑–∞—Ü—ã
    unique_texts: List[str] = []
    seen: Set[str] = set()
    for s in cleaned:
        if s not in seen:
            seen.add(s)
            unique_texts.append(s)

    if not unique_texts:
        return {}

    # –ü—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º –∫–∞–∂–¥–æ–º—É —É–Ω–∏–∫–∞–ª—å–Ω–æ–º—É —Ç–µ–∫—Å—Ç—É —á–∏—Å–ª–æ–≤–æ–π ID
    id_to_text: Dict[int, str] = {i: txt for i, txt in enumerate(unique_texts)}
    text_to_id: Dict[str, int] = {txt: i for i, txt in id_to_text.items()}

    print(f"–î–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ —á–µ—Ä–µ–∑ ChatGPT –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(unique_texts)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤.")

    BATCH_SIZE = 200
    total = len(unique_texts)
    done = 0

    # —Å—é–¥–∞ –±—É–¥–µ–º —Å–æ–±–∏—Ä–∞—Ç—å –ø–µ—Ä–µ–≤–æ–¥—ã –ø–æ ID
    id_to_translated: Dict[int, str] = {}

    for batch_ids in chunks(list(id_to_text.keys()), BATCH_SIZE):
        batch_items = [
            {"id": i, "text": id_to_text[i]}
            for i in batch_ids
        ]

        if progress_callback and total > 0:
            frac = done / total
            pct = start + (end - start) * frac
            progress_callback(pct, "–ü–µ—Ä–µ–≤–æ–¥ —á–µ—Ä–µ–∑ ChatGPT...")

        user_payload = {
            "source_language": "Georgian",
            "target_language": target_language,
            "items": batch_items,
        }

        system_msg = (
            "You are a professional legal and technical translator. "
            "The texts are official documents (tariff methodology, regulatory acts, explanatory notes). "
            f"Translate from Georgian to {target_language} into natural, formal, human-quality {target_language}. "
            "You MAY freely change word order, grammar, and morphology so that the result sounds like good native legal language, "
            "but you MUST preserve all facts, numbers, names, and logical relations. "
            "Avoid literal calques from Georgian where they sound unnatural in the target language. "
            "DO NOT merge separate words together: always keep proper spaces between words, "
            "between prepositions and nouns, and around conjunctions (like '–∏', '·Éì·Éê', 'and', etc.). "
            "Fix any missing spaces if they are present in the original. "
            "Do NOT explicitly mention grammatical cases or parts of speech. "
            "Return ONLY a JSON object with a single key 'translations', whose value is a list of objects "
            "of the form {\"id\": <same id>, \"text\": <translation>}. "
            "Do not add extra fields."
        )

        resp = client.chat.completions.create(
            model=model_name,
            response_format={"type": "json_object"},
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": json.dumps(user_payload, ensure_ascii=False)},
            ],
        )

        content = resp.choices[0].message.content
        try:
            data = json.loads(content)
        except json.JSONDecodeError:
            print("‚ö†Ô∏è –û—à–∏–±–∫–∞ JSON –æ—Ç –º–æ–¥–µ–ª–∏, –æ—Ç–≤–µ—Ç:")
            print(content)
            raise

        translations_list = data.get("translations")
        if not isinstance(translations_list, list):
            raise ValueError("–û–∂–∏–¥–∞–ª—Å—è –∫–ª—é—á 'translations' —Å–æ —Å–ø–∏—Å–∫–æ–º –æ–±—ä–µ–∫—Ç–æ–≤ {id, text}.")

        for obj in translations_list:
            if not isinstance(obj, dict):
                continue
            tid = obj.get("id")
            ttext = obj.get("text")
            try:
                tid_int = int(tid)
            except (TypeError, ValueError):
                continue
            if not isinstance(ttext, str) or not ttext.strip():
                # –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –¥–∞–ª–∞ –ø–µ—Ä–µ–≤–æ–¥ ‚Äî –æ—Å—Ç–∞–≤–∏–º –∫–∞–∫ –µ—Å—Ç—å (–ø–æ–¥—Å—Ç–∞–≤–∏–º –ø–æ–∑–∂–µ)
                continue
            id_to_translated[tid_int] = ttext

        done += len(batch_ids)
        print(f"   ChatGPT –ø–µ—Ä–µ–≤—ë–ª {done}/{total} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤")

        if progress_callback and total > 0:
            frac = done / total
            pct = start + (end - start) * frac
            progress_callback(pct, "–ü–µ—Ä–µ–≤–æ–¥ —á–µ—Ä–µ–∑ ChatGPT...")

    # 2) –°–æ–±–∏—Ä–∞–µ–º –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω—ã–π mapping {–∏—Å—Ö–æ–¥–Ω—ã–π_—Ç–µ–∫—Å—Ç -> –ø–µ—Ä–µ–≤–æ–¥}
    mapping: Dict[str, str] = {}
    for txt, tid in text_to_id.items():
        trans = id_to_translated.get(tid)
        if isinstance(trans, str) and trans.strip():
            # –ù–ò–ß–ï–ì–û –Ω–µ –ø—Ä–∞–≤–∏–º: –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–≤–æ–¥ –∫–∞–∫ –µ—Å—Ç—å
            mapping[txt] = trans
        else:
            mapping[txt] = txt

    return mapping


def post_edit_with_chatgpt(
    mapping: Dict[str, str],
    model_name: str,
    api_key: str,
    target_language: str,
    progress_callback: Optional[Callable[[float, str], None]] = None,
    start: float = 70.0,
    end: float = 90.0,
) -> Dict[str, str]:
    """
    –õ–∏—Ç–µ—Ä–∞—Ç—É—Ä–Ω–∞—è –≤—ã—á–∏—Ç–∫–∞ —É–∂–µ –ø–µ—Ä–µ–≤–µ–¥—ë–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.
    mapping: {–≥—Ä—É–∑–∏–Ω—Å–∫–∏–π_–æ—Ä–∏–≥–∏–Ω–∞–ª -> –º–∞—à–∏–Ω–Ω—ã–π_–ø–µ—Ä–µ–≤–æ–¥}
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ—Ç –∂–µ mapping, –Ω–æ –∑–Ω–∞—á–µ–Ω–∏—è —Å–≥–ª–∞–∂–µ–Ω—ã.
    """
    from openai import OpenAI

    os.environ["OPENAI_API_KEY"] = api_key
    client = OpenAI()

    unique_values: List[str] = []
    seen = set()
    for v in mapping.values():
        if v not in seen and v.strip():
            seen.add(v)
            unique_values.append(v)

    if not unique_values:
        return mapping

    BATCH_SIZE = 200
    total = len(unique_values)
    done = 0

    improved_map: Dict[str, str] = {}

    for batch in chunks(unique_values, BATCH_SIZE):
        if progress_callback and total > 0:
            frac = done / total
            pct = start + (end - start) * frac
            progress_callback(pct, "–õ–∏—Ç–µ—Ä–∞—Ç—É—Ä–Ω–∞—è –≤—ã—á–∏—Ç–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞...")

        user_payload = {
            "target_language": target_language,
            "texts": batch,
        }

        system_msg = (
            "You are a professional editor for legal, regulatory and technical documents. "
            f"Improve style, clarity, grammar and fluency in {target_language} while preserving the same meaning, facts, numbers and legal content. "
            "You MAY change word order, fix awkward literal phrases, adjust cases and morphology, "
            "replace unnatural calques with standard legal expressions, and break or merge sentences if it improves readability. "
            "In addition, you MUST carefully fix spacing: "
            "add missing spaces between words, between prepositions and the following words, "
            "between numbers and words (like '–æ—Ç 4 –¥–µ–∫–∞–±—Ä—è', '‚Ññ 33'), and after punctuation marks where appropriate. "
            "Do NOT merge distinct words together. "
            "Do NOT add new facts or remove existing ones. "
            "Avoid explicit linguistic labels like '—Ä–æ–¥–∏—Ç–µ–ª—å–Ω—ã–π –ø–∞–¥–µ–∂' or explanations of grammar. "
            "Return ONLY a JSON object mapping each original text to its improved version. "
            "Keys MUST be EXACTLY the original texts. Do not add extra fields."
        )

        resp = client.chat.completions.create(
            model=model_name,
            response_format={"type": "json_object"},
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": json.dumps(user_payload, ensure_ascii=False)},
            ],
        )

        content = resp.choices[0].message.content
        try:
            data = json.loads(content)
        except json.JSONDecodeError:
            print("‚ö†Ô∏è –û—à–∏–±–∫–∞ JSON –æ—Ç –º–æ–¥–µ–ª–∏ (–≤—ã—á–∏—Ç–∫–∞), –æ—Ç–≤–µ—Ç:")
            print(content)
            raise

        for orig_text in batch:
            new_text = data.get(orig_text)
            if isinstance(new_text, str) and new_text.strip():
                # –ù–ï —Ç—Ä–æ–≥–∞–µ–º –ø—Ä–æ–±–µ–ª—ã —Ä–µ–≥—ç–∫—Å–∞–º–∏, –±–µ—Ä—ë–º –∫–∞–∫ –µ—Å—Ç—å
                improved_map[orig_text] = new_text
            else:
                improved_map[orig_text] = orig_text

        done += len(batch)
        print(f"   ChatGPT –≤—ã—á–∏—Ç–∞–ª {done}/{total} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤")

        if progress_callback and total > 0:
            frac = done / total
            pct = start + (end - start) * frac
            progress_callback(pct, "–õ–∏—Ç–µ—Ä–∞—Ç—É—Ä–Ω–∞—è –≤—ã—á–∏—Ç–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞...")

    new_mapping: Dict[str, str] = {}
    for geo, raw_trans in mapping.items():
        new_mapping[geo] = improved_map.get(raw_trans, raw_trans)

    return new_mapping

def fix_spacing_with_chatgpt(
    mapping: Dict[str, str],
    model_name: str,
    api_key: str,
    progress_callback: Optional[Callable[[float, str], None]] = None,
    start: float = 70.0,
    end: float = 90.0,
) -> Dict[str, str]:
    """
    –ê–∫–∫—É—Ä–∞—Ç–Ω–∞—è –ø—Ä–∞–≤–∫–∞ –ü–†–û–ë–ï–õ–û–í –≤ —É–∂–µ –ø–µ—Ä–µ–≤–µ–¥—ë–Ω–Ω–æ–º —Ä—É—Å—Å–∫–æ–º —Ç–µ–∫—Å—Ç–µ.
    –í–∞–∂–Ω–æ: –º–æ–¥–µ–ª—å –ù–ï –ò–ú–ï–ï–¢ –ü–†–ê–í–ê –º–µ–Ω—è—Ç—å –∫–∞–∫–∏–µ-–ª–∏–±–æ —Å–∏–º–≤–æ–ª—ã, –∫—Ä–æ–º–µ –æ–±—ã—á–Ω—ã—Ö –ø—Ä–æ–±–µ–ª–æ–≤ U+0020.
    mapping: {–≥—Ä—É–∑–∏–Ω—Å–∫–∏–π_–æ—Ä–∏–≥–∏–Ω–∞–ª -> —Ä—É—Å—Å–∫–∏–π_–ø–µ—Ä–µ–≤–æ–¥}
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç mapping —Å —Ç–µ–º–∏ –∂–µ –∫–ª—é—á–∞–º–∏, –Ω–æ –∑–Ω–∞—á–µ–Ω–∏—è —Å –ø–æ–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–º–∏ –ø—Ä–æ–±–µ–ª–∞–º–∏.
    """
    from openai import OpenAI

    os.environ["OPENAI_API_KEY"] = api_key
    client = OpenAI()

    # –°–æ–±–∏—Ä–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ä—É—Å—Å–∫–∏–µ —Å—Ç—Ä–æ–∫–∏
    unique_values: List[str] = []
    seen = set()
    for v in mapping.values():
        if isinstance(v, str) and v not in seen and v.strip():
            seen.add(v)
            unique_values.append(v)

    if not unique_values:
        return mapping

    BATCH_SIZE = 200
    total = len(unique_values)
    done = 0

    fixed_map: Dict[str, str] = {}

    for batch in chunks(unique_values, BATCH_SIZE):
        if progress_callback and total > 0:
            frac = done / total
            pct = start + (end - start) * frac
            progress_callback(pct, "–ü—Ä–∞–≤–∫–∞ –ø—Ä–æ–±–µ–ª–æ–≤ –≤ —Ä—É—Å—Å–∫–æ–º —Ç–µ–∫—Å—Ç–µ...")

        user_payload = {
            "texts": batch,
        }

        system_msg = (
            "You receive Russian texts which are already translated correctly. "
            "Your ONLY task is to fix spacing errors: insert or delete ASCII space characters (U+0020) "
            "where necessary between words, numbers and punctuation, and collapse multiple spaces to single ones if appropriate. "
            "You MUST NOT change, delete, reorder or insert ANY non-space characters (letters, digits, punctuation). "
            "The sequence of all non-space characters must remain EXACTLY the same and in the same order. "
            "Return ONLY a JSON object mapping each original string to its corrected version. "
            "Keys MUST be EXACTLY the original strings. Do not add extra fields."
        )

        resp = client.chat.completions.create(
            model=model_name,
            response_format={"type": "json_object"},
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": json.dumps(user_payload, ensure_ascii=False)},
            ],
        )

        content = resp.choices[0].message.content
        try:
            data = json.loads(content)
        except json.JSONDecodeError:
            print("‚ö†Ô∏è –û—à–∏–±–∫–∞ JSON –æ—Ç –º–æ–¥–µ–ª–∏ (fix_spacing), –æ—Ç–≤–µ—Ç:")
            print(content)
            raise

        # data: {original_text -> fixed_text}
        for orig_text in batch:
            new_text = data.get(orig_text)
            if isinstance(new_text, str) and new_text.strip():
                fixed_map[orig_text] = new_text
            else:
                fixed_map[orig_text] = orig_text

        done += len(batch)
        print(f"   ChatGPT –ø–æ–ø—Ä–∞–≤–∏–ª –ø—Ä–æ–±–µ–ª—ã –≤ {done}/{total} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ö")

        if progress_callback and total > 0:
            frac = done / total
            pct = start + (end - start) * frac
            progress_callback(pct, "–ü—Ä–∞–≤–∫–∞ –ø—Ä–æ–±–µ–ª–æ–≤ –≤ —Ä—É—Å—Å–∫–æ–º —Ç–µ–∫—Å—Ç–µ...")

    # –°–æ–±–∏—Ä–∞–µ–º –Ω–æ–≤—ã–π mapping: –≥—Ä—É–∑–∏–Ω—Å–∫–∏–π -> —Ä—É—Å—Å–∫–∏–π(—Å –Ω–æ—Ä–º–∞–ª—å–Ω—ã–º–∏ –ø—Ä–æ–±–µ–ª–∞–º–∏)
    new_mapping: Dict[str, str] = {}
    for geo, ru in mapping.items():
        if isinstance(ru, str):
            new_mapping[geo] = fixed_map.get(ru, ru)
        else:
            new_mapping[geo] = ru

    return new_mapping


def translate_with_local_model(
    fragments: List[str],
    direction_code: str,
    progress_callback: Optional[Callable[[float, str], None]] = None,
    start: float = 10.0,
    end: float = 90.0,
) -> Dict[str, str]:
    """
    –õ–æ–∫–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ —á–µ—Ä–µ–∑ Helsinki-NLP –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è:
    ka-ru -> opus-mt-ka-ru
    ka-en -> opus-mt-ka-en
    –¢—Ä–µ–±—É–µ—Ç—Å—è: pip install transformers torch sentencepiece
    """
    from transformers import MarianMTModel, MarianTokenizer
    import torch

    meta = DIRECTION_CONFIG[direction_code]
    MODEL_NAME = meta["local_model"]

    print(f"‚è≥ –ó–∞–≥—Ä—É–∂–∞–µ–º –ª–æ–∫–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å ({MODEL_NAME})...")
    if progress_callback:
        progress_callback(start, "–ó–∞–≥—Ä—É–∑–∫–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏...")

    tokenizer = MarianTokenizer.from_pretrained(MODEL_NAME)
    model = MarianMTModel.from_pretrained(MODEL_NAME)

    mapping: Dict[str, str] = {}
    BATCH_SIZE = 64

    remaining = [f for f in fragments if f.strip()]
    total = len(remaining)
    done = 0

    for batch in chunks(remaining, BATCH_SIZE):
        inputs = tokenizer(batch, return_tensors="pt", padding=True, truncation=True)
        with torch.no_grad():
            generated = model.generate(**inputs, max_length=512)
        outputs = tokenizer.batch_decode(generated, skip_special_tokens=True)

        for orig, trans in zip(batch, outputs):
            mapping[orig] = trans if trans.strip() else orig

        done += len(batch)
        print(f"   –õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –ø–µ—Ä–µ–≤–µ–ª–∞ {done}/{total} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤")

        if progress_callback and total > 0:
            frac = done / total
            pct = start + (end - start) * frac
            progress_callback(pct, "–ü–µ—Ä–µ–≤–æ–¥ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª—å—é...")

    return mapping


def normalize_segment_boundaries(segments: List[str]) -> List[str]:
    """
    –û—á–µ–Ω—å –∞–∫–∫—É—Ä–∞—Ç–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≥—Ä–∞–Ω–∏—Ü:
    - –ù–ï –¥–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–µ –ø—Ä–æ–±–µ–ª—ã —Ç–∞–º, –≥–¥–µ –∏—Ö –Ω–µ –±—ã–ª–æ;
    - —Ç–æ–ª—å–∫–æ:
        * —Å—Ö–ª–æ–ø—ã–≤–∞–µ—Ç –ø–∞—á–∫–∏ –ø—Ä–æ–±–µ–ª–æ–≤ –≤ –∫–æ–Ω—Ü–µ/–Ω–∞—á–∞–ª–µ —Å–µ–≥–º–µ–Ω—Ç–æ–≤;
        * –µ—Å–ª–∏ left –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –ø—Ä–æ–±–µ–ª–æ–º –∏ right –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –ø—Ä–æ–±–µ–ª–æ–º ‚Äî
          —É–±–∏—Ä–∞–µ—Ç –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ right (–æ—Å—Ç–∞–≤–ª—è—è –æ–¥–∏–Ω —Å–æ —Å—Ç–æ—Ä–æ–Ω—ã left).
    """
    if len(segments) <= 1:
        return segments

    segs = segments[:]

    for i in range(len(segs) - 1):
        left = segs[i]
        right = segs[i + 1]

        # —Å—Ö–ª–æ–ø—ã–≤–∞–µ–º –ø–∞—á–∫–∏ –ø—Ä–æ–±–µ–ª–æ–≤ –í–ù–£–¢–†–ò —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –∏ –Ω–∞ –∫—Ä–∞—è—Ö
        left = re.sub(r' {2,}', ' ', left)
        right = re.sub(r' {2,}', ' ', right)

        # –µ—Å–ª–∏ left –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –ø—Ä–æ–±–µ–ª–æ–º –∏ right –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –ø—Ä–æ–±–µ–ª–æ–º ‚Äî
        # –æ—Å—Ç–∞–≤–ª—è–µ–º –æ–¥–∏–Ω (—Å–æ —Å—Ç–æ—Ä–æ–Ω—ã left)
        if left.endswith(" ") and right.startswith(" "):
            right = right.lstrip()

        segs[i] = left
        segs[i + 1] = right

    return segs

def fix_basic_spacing_ru(text: str) -> str:
    """
    –õ—ë–≥–∫–∞—è –ø—Ä–∞–≤–∫–∞ –æ—á–µ–≤–∏–¥–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤ —Ç–∏–ø–∞ '‚Ññ33', '2020–≥–æ–¥–∞', –∑–∞–ø—è—Ç–∞—è –±–µ–∑ –ø—Ä–æ–±–µ–ª–∞ –∏ —Ç.–ø.
    –ë–µ–∑ —Å–ª–æ–≤–∞—Ä–µ–π, —Ç–æ–ª—å–∫–æ –ø—Ä–æ—Å—Ç—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã.
    """
    import re

    text = text.replace("\u00A0", " ")

    # "–ì—Ä—É–∑–∏–∏‚Ññ33" -> "–ì—Ä—É–∑–∏–∏ ‚Ññ33"
    text = re.sub(r'([–ê-–Ø–Å–∞-—è—ë])‚Ññ\s*(\d)', r'\1 ‚Ññ\2', text)
    text = re.sub(r'‚Ññ\s*(\d)', r'‚Ññ \1', text)

    # –ø—Ä–µ–¥–ª–æ–≥ + —á–∏—Å–ª–æ ("–æ—Ç4" -> "–æ—Ç 4")
    text = re.sub(r'(?i)\b(–æ—Ç|–¥–æ|–ø–æ|–Ω–∞|–≤|–∫|—Å|—É)(\d)', r'\1 \2', text)

    # —á–∏—Å–ª–æ + —Å–ª–æ–≤–æ ("4–¥–µ–∫–∞–±—Ä—è" -> "4 –¥–µ–∫–∞–±—Ä—è")
    text = re.sub(r'(\d)([–ê-–Ø–Å–∞-—è—ë])', r'\1 \2', text)

    # —á–∏—Å–ª–æ + "–≥–æ–¥/–≥–æ–¥—ã/–≥–≥."
    text = re.sub(r'(\d{3,4})\s*(–≥–æ–¥[–∞—É–µ]?|–≥–≥?\.?)', r'\1 \2', text)

    # –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è –±–µ–∑ –ø—Ä–æ–±–µ–ª–∞ –ø–æ—Å–ª–µ
    text = re.sub(r',([^\s])', r', \1', text)
    text = re.sub(r';([^\s])', r'; \1', text)
    text = re.sub(r'([^.])\.([–ê-–Ø–Å])', r'\1. \2', text)

    # –ø—Ä–æ—Ü–µ–Ω—Ç—ã
    text = re.sub(r'(%)([–ê-–Ø–Å–∞-—è—ë])', r'\1 \2', text)

    # —Å—Ö–ª–æ–ø—ã–≤–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ –ø–∞—á–∫–∏ –ø—Ä–æ–±–µ–ª–æ–≤
    text = re.sub(r'[ \t]{2,}', ' ', text)

    return text


# ============ –õ–æ–≥–∏–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ ============

def process_file(
    file_path: str,
    translator_kind: str,
    chatgpt_model: str,
    env_path: Optional[str],
    direction_code: str,
    post_edit: bool,
    progress_callback: Optional[Callable[[float, str], None]] = None,
) -> str:
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: —Å–æ–±–∏—Ä–∞–µ—Ç —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã, –ø–µ—Ä–µ–≤–æ–¥–∏—Ç –≤—ã–±—Ä–∞–Ω–Ω—ã–º –¥–≤–∏–∂–∫–æ–º,
    –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –¥–µ–ª–∞–µ—Ç –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–Ω—É—é –≤—ã—á–∏—Ç–∫—É,
    –ø—Ä–∏–º–µ–Ω—è–µ—Ç –ø–µ—Ä–µ–≤–æ–¥—ã, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É.
    """

    if progress_callback is None:
        def progress_callback(pct: float, msg: str) -> None:
            pass  # –∑–∞–≥–ª—É—à–∫–∞

    if not (is_docx(file_path) or is_xlsx(file_path)):
        raise ValueError("–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª—ã .docx –∏ .xlsx")

    if direction_code not in DIRECTION_CONFIG:
        raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: {direction_code}")

    meta = DIRECTION_CONFIG[direction_code]
    target_language = meta["target_language"]
    suffix = meta["suffix"]

    # 1. –°–±–æ—Ä —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤
    progress_callback(0.0, "–°–±–æ—Ä –≥—Ä—É–∑–∏–Ω—Å–∫–∏—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤...")

    if is_docx(file_path):
        items = collect_docx_items(file_path)
        if not items:
            progress_callback(0.0, "–ì—Ä—É–∑–∏–Ω—Å–∫–∏–π —Ç–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω.")
            raise RuntimeError("–í —Ñ–∞–π–ª–µ –Ω–µ –Ω–∞–π–¥–µ–Ω –≥—Ä—É–∑–∏–Ω—Å–∫–∏–π —Ç–µ–∫—Å—Ç –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞.")

        # 1) –∞–±–∑–∞—Ü—ã (–∫–∞–∫ –∏ –±—ã–ª–æ)
        base_texts = {str(it["clean_text"]) for it in items}

        # 2) –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–û: –ª—é–±—ã–µ –≥—Ä—É–∑–∏–Ω—Å–∫–∏–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –∏–∑ –≤—Å–µ—Ö *.xml –≤–Ω—É—Ç—Ä–∏ docx
        extra_texts: Set[str] = set()
        with zipfile.ZipFile(file_path, "r") as zin:
            for info in zin.infolist():
                fname = info.filename
                if not fname.lower().endswith(".xml"):
                    continue

                xml_bytes = zin.read(fname)
                extra_texts.update(collect_georgian_fragments_from_xml_bytes(xml_bytes))

        # –æ–±—ä–µ–¥–∏–Ω—è–µ–º
        all_texts = base_texts | extra_texts

        # –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –µ—â—ë —Ä–∞–∑ —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –≥—Ä—É–∑–∏–Ω—Å–∫–æ–º—É (–µ—Å–ª–∏ –≤–¥—Ä—É–≥ —á—Ç–æ-—Ç–æ –ø—Ä–æ–ª–µ–∑–ª–æ)
        fragments_for_translation = sorted(
            t for t in all_texts
            if t.strip() and GEORGIAN_RE.search(t)
        )

        items_for_docx = items  # —Å–æ—Ö—Ä–∞–Ω–∏–º, —á—Ç–æ–±—ã –ø–æ—Ç–æ–º –ø–æ—Å—Ç—Ä–æ–∏—Ç—å id_mapping
    else:
        # XLSX ‚Äî –∫–∞–∫ —Ä–∞–Ω—å—à–µ, –ø—Ä–æ—Å—Ç–æ –º–Ω–æ–∂–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫
        fragments_set = collect_fragments_xlsx(file_path)
        if not fragments_set:
            progress_callback(0.0, "–ì—Ä—É–∑–∏–Ω—Å–∫–∏–π —Ç–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω.")
            raise RuntimeError("–í —Ñ–∞–π–ª–µ –Ω–µ –Ω–∞–π–¥–µ–Ω –≥—Ä—É–∑–∏–Ω—Å–∫–∏–π —Ç–µ–∫—Å—Ç –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞.")
        fragments_for_translation = sorted(fragments_set)
        items = None  # –¥–ª—è XLSX –Ω–µ –Ω—É–∂–Ω–æ

    print(f"–ù–∞–π–¥–µ–Ω–æ {len(fragments_for_translation)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞.")
    progress_callback(5.0, f"–ù–∞–π–¥–µ–Ω–æ {len(fragments_for_translation)} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –ø–µ—Ä–µ–≤–æ–¥—É...")

    # 2. –ü–µ—Ä–µ–≤–æ–¥
    if translator_kind == "chatgpt":
        if not env_path:
            raise ValueError("–ù–µ –≤—ã–±—Ä–∞–Ω .env —Ñ–∞–π–ª —Å —Ç–æ–∫–µ–Ω–æ–º –¥–ª—è ChatGPT.")
        api_key = load_api_key_from_env_file(env_path)

        mapping_text_to_trans = translate_with_chatgpt(
            fragments_for_translation,
            chatgpt_model,
            api_key,
            target_language,
            progress_callback=progress_callback,
            start=10.0,
            end=60.0,
        )

        # –ë–æ–ª—å—à–µ –ù–ò–ö–ê–ö–ò–• –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∞–≤–æ–∫ –ø—Ä–æ–±–µ–ª–æ–≤ –∑–¥–µ—Å—å.
        # –ï—Å–ª–∏ —Ö–æ—á–µ—à—å, –ø–æ—Å—Ç-—Ä–µ–¥–∞–∫—Ç—É—Ä—É –º–æ–∂–Ω–æ –≤–∫–ª—é—á–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω–æ (–Ω–æ –æ–Ω–∞ –º–æ–∂–µ—Ç –º–µ–Ω—è—Ç—å –ø—Ä–æ–±–µ–ª—ã).
        if post_edit:
            mapping_text_to_trans = post_edit_with_chatgpt(
                mapping_text_to_trans,
                chatgpt_model,
                api_key,
                target_language,
                progress_callback=progress_callback,
                start=60.0,
                end=90.0,
            )

    else:
        # –õ–æ–∫–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ –±–µ–∑ ChatGPT-–ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∏
        mapping_text_to_trans = translate_with_local_model(
            fragments_for_translation,
            direction_code,
            progress_callback=progress_callback,
            start=10.0,
            end=90.0,
        )

    # 2b. –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –º–∞–ø–ø–∏–Ω–≥ –¥–ª—è DOCX –≤ —Ñ–æ—Ä–º–∞—Ç id -> translation
    if is_docx(file_path):
        id_mapping: Dict[str, str] = {}
        for it in items:  # type: ignore
            clean_text = str(it["clean_text"])
            item_id = str(it["id"])
            translated = mapping_text_to_trans.get(clean_text, clean_text)
            id_mapping[item_id] = translated
    else:
        id_mapping = mapping_text_to_trans  # –¥–ª—è XLSX –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π mapping

    # 3. –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–µ—Ä–µ–≤–æ–¥—ã –∫ —Ñ–∞–π–ª—É
    base, ext = os.path.splitext(file_path)
    output_path = f"{base}{suffix}{ext}"

    progress_callback(90.0, "–ü—Ä–∏–º–µ–Ω—è–µ–º –ø–µ—Ä–µ–≤–æ–¥—ã –∫ —Ñ–∞–π–ª—É...")
    if is_docx(file_path):
        apply_translations_docx(
            file_path,
            output_path,
            id_mapping,
            mapping_text_to_trans,  # <-- –≤–æ—Ç —ç—Ç–æ –≤–∞–∂–Ω–æ–µ
            progress_callback=progress_callback,
            start=90.0,
            end=100.0,
        )
    else:
        apply_translations_xlsx(
            file_path,
            output_path,
            id_mapping,
            progress_callback=progress_callback,
            start=90.0,
            end=100.0,
        )

    progress_callback(100.0, "–ì–æ—Ç–æ–≤–æ.")
    if is_docx(output_path):
        debug_scan_docx_for_georgian(output_path)

    return output_path


# ============ GUI (Tkinter) ============

class TranslatorGUI:
    def __init__(self, root: tk.Tk):
        self.root = root
        self.root.title("–ü–µ—Ä–µ–≤–æ–¥ –≥—Ä—É–∑–∏–Ω—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –≤ DOCX/XLSX")

        self.file_path_var = tk.StringVar()
        self.env_path_var = tk.StringVar()
        self.translator_var = tk.StringVar(value="chatgpt")
        self.model_var = tk.StringVar(value=DEFAULT_CHATGPT_MODEL)
        self.direction_label_var = tk.StringVar(value=DIRECTION_CONFIG["ka-ru"]["label"])

        self.progress_var = tk.DoubleVar(value=0.0)
        self.status_var = tk.StringVar(value="–ì–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ.")

        self.post_edit_var = tk.BooleanVar(value=False)  # —á–µ–∫–±–æ–∫—Å –≤—ã—á–∏—Ç–∫–∏

        self.start_button: Optional[ttk.Button] = None
        self.post_edit_check: Optional[ttk.Checkbutton] = None

        self.build_ui()

    def build_ui(self):
        pad = 5

        frm = ttk.Frame(self.root, padding=10)
        frm.grid(row=0, column=0, sticky="nsew")

        # --- –≤—ã–±–æ—Ä —Ñ–∞–π–ª–∞ ---
        ttk.Label(frm, text="–§–∞–π–ª DOCX/XLSX:").grid(row=0, column=0, sticky="w", pady=pad)
        entry_file = ttk.Entry(frm, textvariable=self.file_path_var, width=60)
        entry_file.grid(row=0, column=1, sticky="we", pady=pad)
        ttk.Button(frm, text="–í—ã–±—Ä–∞—Ç—å...", command=self.choose_file).grid(row=0, column=2, padx=pad, pady=pad)

        # --- –≤—ã–±–æ—Ä —Ç–∏–ø–∞ –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–∞ ---
        ttk.Label(frm, text="–ü–µ—Ä–µ–≤–æ–¥—á–∏–∫:").grid(row=1, column=0, sticky="w", pady=pad)

        r1 = ttk.Radiobutton(
            frm,
            text="ChatGPT (–æ–±–ª–∞—á–Ω—ã–π)",
            variable=self.translator_var,
            value="chatgpt",
            command=self.on_translator_change,
        )
        r1.grid(row=1, column=1, sticky="w", pady=pad)

        r2 = ttk.Radiobutton(
            frm,
            text="–õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å (Helsinki-NLP)",
            variable=self.translator_var,
            value="local",
            command=self.on_translator_change,
        )
        r2.grid(row=2, column=1, sticky="w", pady=pad)

        # --- –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–¥–∞ ---
        ttk.Label(frm, text="–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–¥–∞:").grid(row=3, column=0, sticky="w", pady=pad)
        direction_values = [meta["label"] for meta in DIRECTION_CONFIG.values()]
        self.direction_combo = ttk.Combobox(
            frm,
            textvariable=self.direction_label_var,
            values=direction_values,
            state="readonly",
            width=35,
        )
        self.direction_combo.grid(row=3, column=1, sticky="w", pady=pad)

        # --- –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ ChatGPT ---
        ttk.Label(frm, text="–ú–æ–¥–µ–ª—å ChatGPT:").grid(row=4, column=0, sticky="w", pady=pad)
        self.model_combo = ttk.Combobox(
            frm,
            textvariable=self.model_var,
            values=CHATGPT_MODELS,
            state="readonly",
            width=35,
        )
        self.model_combo.grid(row=4, column=1, sticky="w", pady=pad)

        # --- –≤—ã–±–æ—Ä .env —Å —Ç–æ–∫–µ–Ω–æ–º ---
        ttk.Label(frm, text=".env —Å —Ç–æ–∫–µ–Ω–æ–º:").grid(row=5, column=0, sticky="w", pady=pad)
        self.env_entry = ttk.Entry(frm, textvariable=self.env_path_var, width=60)
        self.env_entry.grid(row=5, column=1, sticky="we", pady=pad)
        self.env_button = ttk.Button(frm, text="–í—ã–±—Ä–∞—Ç—å .env...", command=self.choose_env_file)
        self.env_button.grid(row=5, column=2, padx=pad, pady=pad)

        # --- —á–µ–∫–±–æ–∫—Å –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–Ω–æ–π –≤—ã—á–∏—Ç–∫–∏ ---
        self.post_edit_check = ttk.Checkbutton(
            frm,
            text="–õ–∏—Ç–µ—Ä–∞—Ç—É—Ä–Ω–∞—è –≤—ã—á–∏—Ç–∫–∞ (—É–ª—É—á—à–∞—Ç—å —Å—Ç–∏–ª—å –ø–µ—Ä–µ–≤–æ–¥–∞ —á–µ—Ä–µ–∑ ChatGPT)",
            variable=self.post_edit_var,
        )
        self.post_edit_check.grid(row=6, column=0, columnspan=3, sticky="w", pady=pad)

        # --- –ø—Ä–æ–≥—Ä–µ—Å—Å –∏ —Å—Ç–∞—Ç—É—Å ---
        ttk.Label(frm, text="–ü—Ä–æ–≥—Ä–µ—Å—Å:").grid(row=7, column=0, sticky="w", pady=pad)
        self.progress_bar = ttk.Progressbar(
            frm,
            maximum=100.0,
            variable=self.progress_var,
            mode="determinate",
            length=300,
        )
        self.progress_bar.grid(row=7, column=1, columnspan=2, sticky="we", pady=pad)

        self.status_label = ttk.Label(frm, textvariable=self.status_var)
        self.status_label.grid(row=8, column=0, columnspan=3, sticky="w", pady=pad)

        # --- –∫–Ω–æ–ø–∫–∞ –∑–∞–ø—É—Å–∫–∞ ---
        self.start_button = ttk.Button(frm, text="–°—Ç–∞—Ä—Ç –ø–µ—Ä–µ–≤–æ–¥–∞", command=self.run_translation)
        self.start_button.grid(row=9, column=0, columnspan=3, pady=10)

        self.root.columnconfigure(0, weight=1)
        frm.columnconfigure(1, weight=1)

        self.on_translator_change()

    # –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ GUI ‚Äî –¢–û–õ–¨–ö–û –∏–∑ –≥–ª–∞–≤–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞
    def _update_progress_mainthread(self, pct: float, msg: str) -> None:
        self.progress_var.set(max(0.0, min(100.0, pct)))
        self.status_var.set(msg)

    def set_progress(self, pct: float, msg: str) -> None:
        # –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –∏–∑ —Ä–∞–±–æ—á–µ–≥–æ –ø–æ—Ç–æ–∫–∞ ‚Üí –ø—Ä–æ–∫–∏–¥—ã–≤–∞–µ–º —á–µ—Ä–µ–∑ after
        self.root.after(0, self._update_progress_mainthread, pct, msg)

    def choose_file(self):
        path = filedialog.askopenfilename(
            title="–í—ã–±–µ—Ä–∏—Ç–µ DOCX –∏–ª–∏ XLSX",
            filetypes=[("Office files", "*.docx *.xlsx"), ("–í—Å–µ —Ñ–∞–π–ª—ã", "*.*")],
        )
        if path:
            self.file_path_var.set(path)

    def choose_env_file(self):
        path = filedialog.askopenfilename(
            title="–í—ã–±–µ—Ä–∏—Ç–µ .env —Ñ–∞–π–ª —Å OPENAI_API_KEY",
            filetypes=[("ENV files", "*.env;*.txt;*.*"), ("–í—Å–µ —Ñ–∞–π–ª—ã", "*.*")],
        )
        if path:
            self.env_path_var.set(path)

    def on_translator_change(self):
        kind = self.translator_var.get()
        if kind == "chatgpt":
            self.model_combo.configure(state="readonly")
            self.env_entry.configure(state="normal")
            self.env_button.configure(state="normal")
            if self.post_edit_check is not None:
                self.post_edit_check.configure(state="normal")
        else:
            self.model_combo.configure(state="disabled")
            self.env_entry.configure(state="disabled")
            self.env_button.configure(state="disabled")
            self.post_edit_var.set(False)
            if self.post_edit_check is not None:
                self.post_edit_check.configure(state="disabled")

    def run_translation(self):
        file_path = self.file_path_var.get().strip()
        if not file_path:
            messagebox.showerror("–û—à–∏–±–∫–∞", "–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª DOCX/XLSX.")
            return

        if not (is_docx(file_path) or is_xlsx(file_path)):
            messagebox.showerror("–û—à–∏–±–∫–∞", "–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª—ã .docx –∏ .xlsx.")
            return

        translator_kind = self.translator_var.get()
        chatgpt_model = self.model_var.get()
        env_path = self.env_path_var.get().strip() if translator_kind == "chatgpt" else None
        post_edit = bool(self.post_edit_var.get())

        direction_label = self.direction_label_var.get()
        try:
            direction_code = get_direction_code_from_label(direction_label)
        except ValueError as e:
            messagebox.showerror("–û—à–∏–±–∫–∞", str(e))
            return

        if translator_kind == "chatgpt" and not env_path:
            messagebox.showerror("–û—à–∏–±–∫–∞", "–í—ã–±–µ—Ä–∏—Ç–µ .env —Ñ–∞–π–ª —Å —Ç–æ–∫–µ–Ω–æ–º –¥–ª—è ChatGPT.")
            return

        # –±–ª–æ–∫–∏—Ä—É–µ–º –∫–Ω–æ–ø–∫—É –∏ —Å–±—Ä–∞—Å—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
        self.start_button.configure(state="disabled")
        self.set_progress(0.0, "–ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏...")

        # –∑–∞–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–µ–≤–æ–¥ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
        t = threading.Thread(
            target=self._worker_translate,
            args=(file_path, translator_kind, chatgpt_model, env_path, direction_code, post_edit),
            daemon=True,
        )
        t.start()

    def _worker_translate(self, file_path: str, translator_kind: str,
                          chatgpt_model: str, env_path: Optional[str],
                          direction_code: str, post_edit: bool):
        """–†–∞–±–æ—á–∏–π –ø–æ—Ç–æ–∫: –∑–∞–ø—É—Å–∫–∞–µ—Ç process_file –∏ —à–ª—ë—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å –≤ GUI."""
        try:
            output_path = process_file(
                file_path=file_path,
                translator_kind=translator_kind,
                chatgpt_model=chatgpt_model,
                env_path=env_path,
                direction_code=direction_code,
                post_edit=post_edit,
                progress_callback=self.set_progress,
            )
        except Exception as e:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—Å—Ç –æ—à–∏–±–∫–∏, –ø–æ—Ç–æ–º—É —á—Ç–æ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é e –ø–æ—Ç–æ–º —É–¥–∞–ª—è—Ç
            import traceback
            traceback.print_exc()  # —á—Ç–æ–±—ã –≤–∏–¥–µ—Ç—å –ø–æ–ª–Ω—ã–π —Ç—Ä–µ–π—Å –≤ –∫–æ–Ω—Å–æ–ª–∏

            err_msg = f"{type(e).__name__}: {e}"

            def show_error(msg=err_msg):
                self.start_button.configure(state="normal")
                self._update_progress_mainthread(0.0, "–û—à–∏–±–∫–∞.")
                messagebox.showerror("–û—à–∏–±–∫–∞", f"–ü–µ—Ä–µ–≤–æ–¥ –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π:\n{msg}")

            self.root.after(0, show_error)
            return

        def on_done():
            self.start_button.configure(state="normal")
            self._update_progress_mainthread(100.0, "–ì–æ—Ç–æ–≤–æ.")
            messagebox.showinfo("–ì–æ—Ç–æ–≤–æ", f"–§–∞–π–ª –ø–µ—Ä–µ–≤–µ–¥—ë–Ω:\n{output_path}")
        self.root.after(0, on_done)


def main():
    root = tk.Tk()
    TranslatorGUI(root)
    root.mainloop()


if __name__ == "__main__":
    main()
